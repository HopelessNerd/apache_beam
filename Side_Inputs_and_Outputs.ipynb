{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Side Inputs and Outputs.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iNQBGMmi9-pV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPHoW8Gv49i6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Installation\n",
        "Run the following command to install apache-beam\n",
        "\n",
        "Note: To run pipeline on the google colab environemnt, no need to install/configure runners. Each session in the colab is assigned with new virtual environment which forces us to install apache beam every time a new session is created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKGKaSEs48o6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!{'pip install apache-beam'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SqCKeZe5J6g",
        "colab_type": "text"
      },
      "source": [
        "# Upload the required files\n",
        "\n",
        "All the files required to be consumed must be uploaded by the following command. Later transformations could be applied by reading the data file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR6OfrSR5Ksg",
        "colab_type": "code",
        "outputId": "f3b9741a-4cbc-4aaa-a4aa-a82bb28a54ad",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e0dc3dd7-ae38-4043-bec1-559687b80453\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e0dc3dd7-ae38-4043-bec1-559687b80453\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving exclude_ids.txt to exclude_ids.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j9pXQzL5Ogx",
        "colab_type": "text"
      },
      "source": [
        "# Side Inputs\n",
        "\n",
        "In addition to the main input PCollection, you can provide additional inputs to a ParDo transform in the form of side inputs. A side input is an additional input that your DoFn can access each time it processes an element in the input PCollection. When you specify a side input, you create a view of some other data that can be read from within the ParDo transform’s DoFn while processing each element.\n",
        "\n",
        "Side inputs are useful if your ParDo needs to inject additional data when processing each element in the input PCollection, but the additional data needs to be determined at runtime (and not hard-coded). Such values might be determined by the input data, or depend on a different branch of your pipeline.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgWHRYZp6nTW",
        "colab_type": "code",
        "outputId": "deb84886-5f73-4d2e-adb7-1726578cd478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "# Open a file contained a list of ids which needs to excluded and store it in a list object\n",
        "side_list=list()\n",
        "with open ('exclude_ids.txt','r') as my_file:\n",
        "  for line in my_file:\n",
        "    side_list.append(line.rstrip())\n",
        "\n",
        "p = beam.Pipeline()\n",
        "\n",
        "# We can pass side inputs to a ParDo transform, which will get passed to its process method.\n",
        "# The first two arguments for the process method would be self and element.\n",
        "\n",
        "class FilterUsingLength(beam.DoFn):\n",
        "  def process(self, element,side_list,lower_bound, upper_bound=float('inf')):\n",
        "\n",
        "    # Retrive id from a line after spliting it by comma\n",
        "    id = element.split(',')[0]\n",
        "\n",
        "    # Retrive name from a line after spliting it by comma\n",
        "    name = element.split(',')[1]\n",
        "\n",
        "    # Convert line to a list by spliting using comma\n",
        "    element_list= element.split(',')\n",
        "\n",
        "    # Return a list if ids are not in the excluded list and the length of the name is in between 3 and 10\n",
        "    if (lower_bound <= len(name) <= upper_bound) and id not in side_list:\n",
        "      return [element_list]\n",
        "\n",
        "# using pardo to filter names with length between 3 and 10\n",
        "small_names =( \n",
        "                p\n",
        "                # Read text from the file, each element is a line of the file\n",
        "                | \"Read from text file\" >> beam.io.ReadFromText('dept_data.txt')\n",
        "\n",
        "                # Apply the FilterUsingLength function to the ParDo method to filter the ids\n",
        "                | \"ParDo with side inputs\" >> beam.ParDo(FilterUsingLength(),side_list,3,10) \n",
        "\n",
        "                # Also check if the department is Accounts\n",
        "                | beam.Filter(lambda record: record[3] == 'Accounts')\n",
        "\n",
        "                # Apply a value 1 to each employee in a tuple\n",
        "                | beam.Map(lambda record: (record[0]+ \" \" + record[1], 1))\n",
        "\n",
        "                # Run sum on the values \n",
        "                | beam.CombinePerKey(sum)\n",
        "\n",
        "                # Finally write the results to a file\n",
        "                # Results: A tuple containing the key as id + \" \" + name and value as the times of occurences of an employee \n",
        "                | 'Write results' >> beam.io.WriteToText('data/output_new_final')\n",
        "             )\n",
        "\n",
        "p.run()\n",
        "\n",
        "!{('head -n 20 data/output_new_final-00000-of-00001')}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('503996WI Edouard', 31)\n",
            "('957149WC Kyle', 31)\n",
            "('241316NX Kumiko', 31)\n",
            "('796656IE Gaston', 31)\n",
            "('718737IX Ayumi', 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIVfC-oX6_eK",
        "colab_type": "text"
      },
      "source": [
        "# Additional Outputs\n",
        "\n",
        "While ParDo always produces a main output PCollection (as the return value from apply), you can also have your ParDo produce any number of additional output PCollections. If you choose to have multiple outputs, your ParDo returns all of the output PCollections (including the main output) bundled together.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DKnEhiN68zS",
        "colab_type": "code",
        "outputId": "19494517-741e-4000-c64b-d6dd58b69a36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "# Class to inherit the DoFn class of beam\n",
        "class ProcessWords(beam.DoFn):\n",
        "  \n",
        "  # Override the process method to implement the filter logic to separate outputs\n",
        "  def process(self, element, cutoff_length, marker):\n",
        "    \n",
        "    name = element.split(',')[1]\n",
        "\n",
        "    # If name starts with the marker\n",
        "    if name.startswith(marker):\n",
        "      return [name]\n",
        "\n",
        "    # If the length of the name is less than the cutoff\n",
        "    if len(name) <= cutoff_length:\n",
        "      return [beam.pvalue.TaggedOutput('Short_Names', name)]\n",
        "    \n",
        "    # Else if the length is greater than the cutoff\n",
        "    else:\n",
        "      return [beam.pvalue.TaggedOutput('Long_Names', name)]\n",
        "    \n",
        "   \n",
        "      \n",
        "p = beam.Pipeline()\n",
        "\n",
        "results = (\n",
        "            p\n",
        "            # Read from the file, each element has one line of data\n",
        "            | beam.io.ReadFromText('dept_data.txt')\n",
        "\n",
        "            # Apply the ParDo transform with the additional outputs\n",
        "            | beam.ParDo(ProcessWords(), cutoff_length=5, marker='A').with_outputs('Short_Names', 'Long_Names', main='Names_A')\n",
        "\n",
        "          )\n",
        "\n",
        "# Create each collection for each separate additional output from the results pipeline\n",
        "short_collection = results.Short_Names\n",
        "long_collection = results.Long_Names\n",
        "startA_collection = results.Names_A\n",
        "\n",
        "# write to file  \n",
        "short_collection | 'Write 1'>> beam.io.WriteToText('short')\n",
        "\n",
        "# write to file\n",
        "long_collection | 'Write 2'>> beam.io.WriteToText('long')\n",
        "\n",
        "# write to file\n",
        "startA_collection | 'Write 3'>> beam.io.WriteToText('start_a')\n",
        "\n",
        "p.run()\n",
        "print(\"Short:\")\n",
        "!{'head -n 5 short-00000-of-00001'}\n",
        "print(\"\\nLong:\")\n",
        "!{'head -n 5 long-00000-of-00001'}\n",
        "print(\"\\nStarting with A:\")\n",
        "!{'head -n 5 start_a-00000-of-00001'}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Short:\n",
            "Marco\n",
            "Itoe\n",
            "Kyle\n",
            "Kyle\n",
            "Beryl\n",
            "\n",
            "Long:\n",
            "Rebekah\n",
            "Edouard\n",
            "Kumiko\n",
            "Gaston\n",
            "Leslie\n",
            "\n",
            "Starting with A:\n",
            "Ayumi\n",
            "Ayumi\n",
            "Ayumi\n",
            "Ayumi\n",
            "Ayumi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNQBGMmi9-pV",
        "colab_type": "text"
      },
      "source": [
        "# Remove Duplicates (extension to additional outputs)\n",
        "\n",
        "An example to remove duplicates from the additional outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6Bghtlm86Xq",
        "colab_type": "code",
        "outputId": "6acf5ddd-1e46-4bd8-b5bf-8b14e984ed7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "class group_and_remove_duplicates(beam.PTransform):\n",
        "\n",
        "  def expand(self, input_coll):   \n",
        "    a = ( \n",
        "          input_coll\n",
        "          | 'Assign value 1' >> beam.Map(lambda x:(x,1))\n",
        "          | 'Group by key' >> beam.GroupByKey()\n",
        "          | 'Select the first column' >> beam.Map(lambda x: x[0])              \n",
        "    )\n",
        "    return a\n",
        "\n",
        "# Class to inherit the DoFn class of beam\n",
        "class ProcessWords(beam.DoFn):\n",
        "  \n",
        "  # Override the process method to implement the filter logic to separate outputs\n",
        "  def process(self, element, cutoff_length, marker):\n",
        "    \n",
        "    name = element.split(',')[1]\n",
        "\n",
        "    # If name starts with the marker\n",
        "    if name.startswith(marker):\n",
        "      return [name]\n",
        "\n",
        "    # If the length of the name is less than the cutoff\n",
        "    if len(name) <= cutoff_length:\n",
        "      return [beam.pvalue.TaggedOutput('Short_Names', name)]\n",
        "    \n",
        "    # Else if the length is greater than the cutoff\n",
        "    else:\n",
        "      return [beam.pvalue.TaggedOutput('Long_Names', name)]\n",
        "    \n",
        "   \n",
        "      \n",
        "p = beam.Pipeline()\n",
        "\n",
        "results = (\n",
        "            p\n",
        "            # Read from the file, each element has one line of data\n",
        "            | beam.io.ReadFromText('dept_data.txt')\n",
        "\n",
        "            # Apply the ParDo transform with the additional outputs\n",
        "            | beam.ParDo(ProcessWords(), cutoff_length=4, marker='A').with_outputs('Short_Names', 'Long_Names', main='Names_A')\n",
        "\n",
        "          )\n",
        "\n",
        "# Create each collection for each separate additional output from the results pipeline\n",
        "short_collection = results.Short_Names |'Remove duplicates short names' >> group_and_remove_duplicates()                  \n",
        "long_collection = results.Long_Names |'Remove duplicates long names' >> group_and_remove_duplicates()\n",
        "startA_collection = results.Names_A |'Remove duplicates names with marker' >> group_and_remove_duplicates()\n",
        "\n",
        "# write to file  \n",
        "short_collection | 'Write 1'>> beam.io.WriteToText('short')\n",
        "\n",
        "# write to file\n",
        "long_collection | 'Write 2'>> beam.io.WriteToText('long')\n",
        "\n",
        "# write to file\n",
        "startA_collection | 'Write 3'>> beam.io.WriteToText('start_a')\n",
        "\n",
        "p.run()\n",
        "print(\"Short:\")\n",
        "!{'head -n 10 short-00000-of-00001'}\n",
        "print(\"\\nLong:\")\n",
        "!{'head -n 10 long-00000-of-00001'}\n",
        "print(\"\\nStarting with A:\")\n",
        "!{'head -n 10 start_a-00000-of-00001'}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Short:\n",
            "Marco\n",
            "Itoe\n",
            "Kyle\n",
            "Beryl\n",
            "Olga\n",
            "Mindy\n",
            "Vicky\n",
            "Kirk\n",
            "Kaori\n",
            "Oscar\n",
            "\n",
            "Long:\n",
            "Rebekah\n",
            "Edouard\n",
            "Kumiko\n",
            "Gaston\n",
            "Leslie\n",
            "Richard\n",
            "Cristobal\n",
            "Sebastien\n",
            "Valerie\n",
            "Hitomi\n",
            "\n",
            "Starting with A:\n",
            "Ayumi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4WGMCYb-ftU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}